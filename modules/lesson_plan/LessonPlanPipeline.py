import os
import json
import datetime
import re
from typing import Dict, Any, List
from utils.GPTClient import GPTClient
from modules.agents.LessonPlanOutlineAgent import LessonPlanOutlineAgent
from modules.agents.LessonContentWriterAgent import LessonContentWriterAgent

class LessonPlanPipeline:
    def __init__(self, llm: GPTClient):
        self.outline_agent = LessonPlanOutlineAgent(llm)
        self.content_agent = LessonContentWriterAgent(llm)
        
    def create_full_lesson_plan(self, user_prompt: str, chunks: List[Dict]) -> Dict[str, Any]:
        """
        T·∫°o k·∫ø ho·∫°ch b√†i gi·∫£ng ho√†n ch·ªânh t·ª´ prompt v√† chunks
        """
        print(f"\nüéì B·∫Øt ƒë·∫ßu t·∫°o k·∫ø ho·∫°ch b√†i gi·∫£ng...")
        print(f"üìù Prompt: {user_prompt}")
        print(f"üìö C√≥ {len(chunks)} chunks t√†i li·ªáu")
        
        # B∆∞·ªõc 1: T·∫°o outline
        print("\nüìã B∆∞·ªõc 1: T·∫°o khung k·∫ø ho·∫°ch b√†i gi·∫£ng...")
        outline = self.outline_agent.run(user_prompt)
        
        if "L·ªói khi t·∫°o outline" in outline:
            return {"error": f"L·ªói t·∫°o outline: {outline}"}
        
        print("‚úÖ ƒê√£ t·∫°o xong outline")
        
        # Tr√≠ch xu·∫•t th√¥ng tin t·ª´ outline
        mon_hoc, lop, ten_bai = self._extract_info_from_outline(outline)
        print(f"\nüîç ƒê√£ tr√≠ch xu·∫•t: M√¥n {mon_hoc} - L·ªõp {lop} - B√†i '{ten_bai}'")
        
        # B∆∞·ªõc 2: Vi·∫øt n·ªôi dung chi ti·∫øt cho t·ª´ng ph·∫ßn
        print("\nüìù B∆∞·ªõc 2: Vi·∫øt n·ªôi dung chi ti·∫øt...")
        
        sections_to_write = [
            "KH·ªûI ƒê·ªòNG",
            "H√åNH TH√ÄNH KI·∫æN TH·ª®C", 
            "LUY·ªÜN T·∫¨P",
            "V·∫¨N D·ª§NG/M·ªû R·ªòNG"
        ]
        
        detailed_content = {}
        
        for section in sections_to_write:
            print(f"\n   ‚úçÔ∏è ƒêang vi·∫øt ph·∫ßn: {section}")
            content = self.content_agent.run(section, outline, chunks, mon_hoc, lop, ten_bai)
            detailed_content[section] = content
            print(f"   ‚úÖ Ho√†n th√†nh ph·∫ßn {section}")
            # In preview c·ªßa content
            preview = content[:200] + "..." if len(content) > 200 else content
            print(f"   üìù Preview: {preview}")
        
        # B∆∞·ªõc 3: Merge th√†nh markdown ho√†n ch·ªânh
        print("\nüìÑ B∆∞·ªõc 3: T·∫°o file markdown ho√†n ch·ªânh...")
        merged_markdown = self._create_complete_markdown(outline, detailed_content, mon_hoc, lop, ten_bai)
        
        # B∆∞·ªõc 4: K·∫øt h·ª£p t·∫•t c·∫£ d·ªØ li·ªáu
        full_lesson_plan = {
            "outline": outline,
            "detailed_content": detailed_content,
            "complete_markdown": merged_markdown,
            "metadata": {
                "created_at": datetime.datetime.now().isoformat(),
                "chunks_used": len(chunks),
                "original_prompt": user_prompt,
                "mon_hoc": mon_hoc,
                "lop": lop,
                "ten_bai": ten_bai
            }
        }
        
        # B∆∞·ªõc 5: L∆∞u c·∫£ JSON v√† Markdown
        json_path = self._save_lesson_plan(full_lesson_plan)
        md_path = self._save_markdown_plan(merged_markdown, mon_hoc, lop, ten_bai)
        
        full_lesson_plan["output_path"] = json_path
        full_lesson_plan["markdown_path"] = md_path
        
        print(f"\nüéâ HO√ÄN TH√ÄNH!")
        print(f"üìä T·ªïng k·∫øt:")
        print(f"   - Outline: {len(outline)} k√Ω t·ª±")
        print(f"   - Chi ti·∫øt: {len(sections_to_write)} ph·∫ßn")
        print(f"   - S·ª≠ d·ª•ng: {len(chunks)} chunks")
        print(f"   - File JSON: {json_path}")
        print(f"   - File Markdown: {md_path}")
        
        return full_lesson_plan
    
    def _extract_info_from_outline(self, outline: str) -> tuple:
        """
        Tr√≠ch xu·∫•t th√¥ng tin m√¥n h·ªçc, l·ªõp, t√™n b√†i t·ª´ outline
        """
        mon_hoc = ""
        lop = ""
        ten_bai = ""
        
        # T√¨m m√¥n h·ªçc
        mon_match = re.search(r'\*\*M√¥n h·ªçc:\*\*\s*(.+)', outline)
        if mon_match:
            mon_hoc = mon_match.group(1).strip()
        
        # T√¨m l·ªõp
        lop_match = re.search(r'\*\*L·ªõp:\*\*\s*(.+)', outline)
        if lop_match:
            lop = lop_match.group(1).strip()
            
        # T√¨m t√™n b√†i
        bai_match = re.search(r'\*\*B√†i h·ªçc:\*\*\s*(.+)', outline)
        if bai_match:
            ten_bai = bai_match.group(1).strip()
        
        return mon_hoc, lop, ten_bai
    
    def _save_lesson_plan(self, lesson_plan: Dict[str, Any]) -> str:
        """
        L∆∞u k·∫ø ho·∫°ch b√†i gi·∫£ng ra file JSON
        """
        os.makedirs("output_lesson_plans", exist_ok=True)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # L·∫•y t√™n b√†i h·ªçc l√†m t√™n file
        ten_bai = lesson_plan.get("metadata", {}).get("ten_bai", "bai_hoc")
        safe_name = "".join(c for c in ten_bai if c.isalnum() or c in (' ', '-', '_')).rstrip()
        safe_name = safe_name.replace(' ', '_')[:50]  # Gi·ªõi h·∫°n ƒë·ªô d√†i
        
        filename = f"lesson_plan_{safe_name}_{timestamp}.json"
        output_path = os.path.join("output_lesson_plans", filename)
        
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(lesson_plan, f, ensure_ascii=False, indent=2)
        
        return output_path
    
    def _save_markdown_plan(self, markdown_content: str, mon_hoc: str, lop: str, ten_bai: str) -> str:
        """
        L∆∞u k·∫ø ho·∫°ch b√†i gi·∫£ng ra file Markdown
        """
        os.makedirs("output_lesson_plans", exist_ok=True)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # T·∫°o t√™n file markdown
        safe_name = "".join(c for c in ten_bai if c.isalnum() or c in (' ', '-', '_')).rstrip()
        safe_name = safe_name.replace(' ', '_')[:50]
        
        filename = f"lesson_plan_{safe_name}_{timestamp}.md"
        output_path = os.path.join("output_lesson_plans", filename)
        
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(markdown_content)
        
        return output_path
    
    def _create_complete_markdown(self, outline: str, detailed_content: Dict, mon_hoc: str, lop: str, ten_bai: str) -> str:
        """
        T·∫°o file markdown ho√†n ch·ªânh t·ª´ outline v√† detailed content
        """
        # Parse outline ƒë·ªÉ l·∫•y c√°c ph·∫ßn
        outline_sections = self._parse_outline_sections(outline)
        
        # T·∫°o markdown ho√†n ch·ªânh
        md_content = []
        
        # Header
        md_content.append(f"# K·∫æ HO·∫†CH B√ÄI GI·∫¢NG: {ten_bai.upper()}")
        md_content.append("")
        
        # Th√™m outline sections (Th√¥ng tin chung, M·ª•c ti√™u, Chu·∫©n b·ªã, etc.)
        section_order = ["TH√îNG TIN CHUNG", "M·ª§C TI√äU B√ÄI H·ªåC", "CHU·∫®N B·ªä"]
        
        for section_name in section_order:
            if section_name in outline_sections:
                md_content.append(f"## {section_name}")
                md_content.append("")
                
                # Format content v·ªõi xu·ªëng d√≤ng
                content = outline_sections[section_name]
                content = self._format_section_content(content)
                md_content.append(content)
                md_content.append("")
        
        # ‚úÖ B·ªé IV - Ch·ªâ vi·∫øt "TI·∫æN TR√åNH D·∫†Y H·ªåC"
        md_content.append("## TI·∫æN TR√åNH D·∫†Y H·ªåC")
        md_content.append("")
        
        # Mapping sections
        section_mapping = {
            "KH·ªûI ƒê·ªòNG": "A. KH·ªûI ƒê·ªòNG",
            "H√åNH TH√ÄNH KI·∫æN TH·ª®C": "B. H√åNH TH√ÄNH KI·∫æN TH·ª®C", 
            "LUY·ªÜN T·∫¨P": "C. LUY·ªÜN T·∫¨P",
            "V·∫¨N D·ª§NG/M·ªû R·ªòNG": "D. V·∫¨N D·ª§NG/M·ªû R·ªòNG"
        }
        
        for section_key, section_title in section_mapping.items():
            md_content.append(f"### {section_title}")
            md_content.append("")
            
            # ‚úÖ TH√äM n·ªôi dung chi ti·∫øt v·ªõi cleaning to√†n di·ªán
            if section_key in detailed_content:
                content = detailed_content[section_key]
                
                # Clean t·∫•t c·∫£ header l·∫∑p l·∫°i
                content = self._clean_duplicate_headers(content, section_key, section_title)
                
                md_content.append(content)
                md_content.append("")
        
        # ‚úÖ CH·ªà TH√äM ƒê√ÅNH GI√Å - B·ªé G·ª¢I √ù
        if "ƒê√ÅNH GI√Å" in outline_sections:
            md_content.append("## ƒê√ÅNH GI√Å")
            md_content.append("")
            content = self._format_section_content(outline_sections["ƒê√ÅNH GI√Å"])
            md_content.append(content)
            md_content.append("")
        
        # Footer
        timestamp = datetime.datetime.now().strftime("%d/%m/%Y %H:%M")
        md_content.append("*K·∫ø ho·∫°ch b√†i gi·∫£ng ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông b·ªüi EduMate AI - " + timestamp + "*")
        
        return "\n".join(md_content)

    def _clean_duplicate_headers(self, content: str, section_key: str, section_title: str) -> str:
        """
        Clean t·∫•t c·∫£ lo·∫°i header l·∫∑p l·∫°i v√† content kh√¥ng c·∫ßn thi·∫øt
        """
        # ‚úÖ B·ªè t·∫•t c·∫£ header l·∫∑p
        content = re.sub(r'###\s*' + re.escape(section_key), '', content, flags=re.IGNORECASE)
        content = re.sub(r'###\s*' + re.escape(section_title), '', content, flags=re.IGNORECASE)
        content = re.sub(r'####?\s*\*\*?' + re.escape(section_key) + r'\*\*?', '', content, flags=re.IGNORECASE)
        content = re.sub(r'###?\s*PH·∫¶N\s*["\'"]*' + re.escape(section_key) + r'["\'"]*', '', content, flags=re.IGNORECASE)
        
        # ‚úÖ B·ªè "PH√ÇN T√çCH CONTEXT" v√† "C·∫§U TR√öC N·ªòI DUNG"
        content = re.sub(r'####?\s*\*\*?1\.\s*PH√ÇN T√çCH CONTEXT\*\*?.*?(?=####|\n\n|\Z)', '', content, flags=re.DOTALL|re.IGNORECASE)
        content = re.sub(r'####?\s*\*\*?2\.\s*C·∫§U TR√öC N·ªòI DUNG\*\*?', '', content, flags=re.IGNORECASE)
        content = re.sub(r'####?\s*\*\*?PH√ÇN T√çCH CONTEXT\*\*?.*?(?=####|\n\n|\Z)', '', content, flags=re.DOTALL|re.IGNORECASE)
        content = re.sub(r'####?\s*\*\*?C·∫§U TR√öC N·ªòI DUNG\*\*?', '', content, flags=re.IGNORECASE)
        
        # ‚úÖ B·ªè t·∫•t c·∫£ d·∫•u ---
        content = re.sub(r'^---+\s*$', '', content, flags=re.MULTILINE)
        
        # ‚úÖ B·ªè content ph√¢n t√≠ch context
        lines = content.split('\n')
        cleaned_lines = []
        skip_context = False
        
        for line in lines:
            line_lower = line.lower().strip()
            
            # B·ªè qua ph·∫ßn ph√¢n t√≠ch context
            if any(phrase in line_lower for phrase in ['v·ªã tr√≠ c·ªßa ph·∫ßn n√†y', 'm·ª•c ti√™u c·ª• th·ªÉ c·∫ßn ƒë·∫°t', 'ƒë·∫∑c ƒëi·ªÉm t√¢m l√Ω l·ª©a tu·ªïi']):
                skip_context = True
                continue
            
            # K·∫øt th√∫c skip khi g·∫∑p header m·ªõi ho·∫∑c n·ªôi dung th·ª±c
            if skip_context and (line.startswith('**') or line.startswith('####') or 'ho·∫°t ƒë·ªông' in line_lower):
                skip_context = False
            
            if not skip_context and line.strip():
                cleaned_lines.append(line)
        
        return '\n'.join(cleaned_lines).strip()

    def _format_section_content(self, content: str) -> str:
        """
        Format n·ªôi dung section v·ªõi xu·ªëng d√≤ng ph√π h·ª£p
        """
        lines = content.split('\n')
        formatted_lines = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # Th√™m xu·ªëng d√≤ng sau c√°c m·ª•c l·ªõn
            if line.startswith('**') and line.endswith(':**'):
                if formatted_lines:  # Kh√¥ng th√™m d√≤ng tr·ªëng ·ªü ƒë·∫ßu
                    formatted_lines.append("")
                formatted_lines.append(line)
            else:
                formatted_lines.append(line)
        
        return '\n'.join(formatted_lines)
    
    def _parse_outline_sections(self, outline: str) -> Dict[str, str]:
        """
        Parse outline th√†nh c√°c sections
        """
        sections = {}
        lines = outline.split('\n')
        current_section = None
        current_content = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # Detect section headers (#### I., #### II., etc.)
            if line.startswith('####') and any(roman in line for roman in ['I.', 'II.', 'III.', 'IV.', 'V.', 'VI.']):
                # Save previous section
                if current_section and current_content:
                    sections[current_section] = '\n'.join(current_content).strip()
                
                # Start new section
                current_section = line.replace('####', '').strip()
                if '.' in current_section:
                    current_section = current_section.split('.', 1)[1].strip()
                current_content = []
            else:
                if current_section:
                    current_content.append(line)
        
        # Save last section
        if current_section and current_content:
            sections[current_section] = '\n'.join(current_content).strip()
        
        return sections
    
    def _extract_section_outline(self, tien_trinh_content: str, section_key: str) -> str:
        """
        Tr√≠ch xu·∫•t th√¥ng tin outline cho m·ªôt section c·ª• th·ªÉ
        """
        lines = tien_trinh_content.split('\n')
        in_section = False
        section_lines = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # Check if this is our section
            if section_key.upper() in line.upper() and ('**' in line or '#' in line):
                in_section = True
                continue
            
            # Check if we've moved to next section
            if in_section and ('**' in line or '#' in line) and any(other_section in line.upper() for other_section in ['KH·ªûI ƒê·ªòNG', 'H√åNH TH√ÄNH', 'LUY·ªÜN T·∫¨P', 'V·∫¨N D·ª§NG'] if other_section not in section_key.upper()):
                break
                
            if in_section:
                section_lines.append(line)
        
        return '\n'.join(section_lines).strip()