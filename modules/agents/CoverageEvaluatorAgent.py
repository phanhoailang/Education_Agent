import json
import logging
import re
from functools import lru_cache
from typing import List, Set, Dict, Any

from modules.rag_module.datatypes.CoverageAssessment import CoverageAssessment
from modules.rag_module.datatypes.CoverageLevel import CoverageLevel


class CoverageEvaluatorAgent:
    def __init__(self, llm, max_content_length: int = 4000):
        self.llm = llm
        self.max_content_length = max_content_length
        self.logger = logging.getLogger(__name__)

        # Fast heuristic weights
        self.keyword_weight = 0.4
        self.length_weight = 0.3
        self.source_diversity_weight = 0.2
        self.quality_weight = 0.1

        # Thresholds for fast decisions
        self.high_confidence_threshold = 0.8
        self.low_confidence_threshold = 0.3

        # Performance counters
        self.fast_decisions = 0
        self.llm_calls = 0

        # Prompt ƒë·ªìng b·ªô v·ªõi h·ªá INSUFFICIENT/PARTIAL/ADEQUATE/COMPREHENSIVE
        self.prompt = """
        B·∫°n l√† m·ªôt chuy√™n gia gi√°o d·ª•c, c√≥ nhi·ªám v·ª• **ƒë√°nh gi√° n·ªôi dung b√†i gi·∫£ng** v·ªõi th√°i ƒë·ªô khuy·∫øn kh√≠ch, linh ho·∫°t v√† mang t√≠nh x√¢y d·ª±ng.

        ## M·ª§C TI√äU
        ƒê√°nh gi√° m·ª©c ƒë·ªô ƒë·∫ßy ƒë·ªß v√† ch·∫•t l∆∞·ª£ng c·ªßa n·ªôi dung hi·ªán c√≥, nh·∫±m x√°c ƒë·ªãnh xem n·ªôi dung ƒë√≥ ƒë√£ ƒë·ªß c∆° s·ªü ƒë·ªÉ ph√°t tri·ªÉn th√†nh m·ªôt b√†i gi·∫£ng ho√†n ch·ªânh ch∆∞a.

        ## TH√îNG TIN ƒê·∫¶U V√ÄO:
        **Y√™u c·∫ßu b√†i gi·∫£ng**: {request}
        **C√°c ch·ªß ƒë·ªÅ quan tr·ªçng**: {required_topics}
        **N·ªôi dung hi·ªán t·∫°i**: {content}

        ## KHUNG ƒê√ÅNH GI√Å LINH HO·∫†T:
        1. ƒê·ªô bao ph·ªß ch·ªß ƒë·ªÅ (25%): Ki·ªÉm tra c√°c ch·ªß ƒë·ªÅ ch√≠nh, ch·∫•p nh·∫≠n c√°ch ti·∫øp c·∫≠n ƒëa d·∫°ng
        2. Ch·∫•t l∆∞·ª£ng n·ªôi dung (35%): T√≠nh ch√≠nh x√°c c∆° b·∫£n, ƒë·ªô r√µ r√†ng, c√≥ th·ªÉ b·ªï sung sau
        3. T√≠nh kh·∫£ thi b√†i gi·∫£ng (25%): ƒê·ªß √Ω t∆∞·ªüng ch√≠nh ƒë·ªÉ ph√°t tri·ªÉn, c√≥ ti·ªÅm nƒÉng m·ªü r·ªông
        4. Gi√° tr·ªã gi√°o d·ª•c (15%): C√≥ √≠ch cho h·ªçc vi√™n, ph√π h·ª£p v·ªõi m·ª•c ti√™u h·ªçc t·∫≠p

        ## THANG ƒêI·ªÇM
        - INSUFFICIENT (0.0‚Äì0.4)
        - PARTIAL (0.4‚Äì0.7)
        - ADEQUATE (0.7‚Äì0.9)
        - COMPREHENSIVE (0.9‚Äì1.0)

        Tr·∫£ v·ªÅ JSON:
        ```json
        {{
            "level": "insufficient|partial|adequate|comprehensive",
            "score": 0.0,
            "covered_topics": ["topic1", "topic2"],
            "missing_topics": ["topic3"],
            "strengths": ["ƒëi·ªÉm m·∫°nh 1", "ƒëi·ªÉm m·∫°nh 2"],
            "suggestions": ["g·ª£i √Ω c·∫£i thi·ªán 1", "g·ª£i √Ω c·∫£i thi·ªán 2"]
        }}
        ```

        CH·ªà tr·∫£ v·ªÅ JSON h·ª£p l·ªá, kh√¥ng th√™m vƒÉn b·∫£n kh√°c.
    """

        # (tu·ª≥ ch·ªçn) in debug enum hi·ªán c√≥
        try:
            dbg = [f"{e.name} -> {getattr(e,'value','')}" for e in CoverageLevel]
            self.logger.debug("CoverageLevel members: " + " | ".join(dbg))
        except Exception:
            pass

    @lru_cache(maxsize=100)
    def extract_keywords(self, text: str) -> frozenset:
        """Extract v√† cache keywords t·ª´ text (b·ªè d·∫•u, b·ªè stopwords ƒë∆°n gi·∫£n)."""
        import unicodedata
        if not text:
            return frozenset()

        text_norm = unicodedata.normalize('NFD', text.lower())
        text_ascii = ''.join(ch for ch in text_norm if unicodedata.category(ch) != 'Mn')

        words = re.findall(r'\b\w{3,}\b', text_ascii)

        stop_words = {
            'the', 'and', 'hoac', 'cua', 'voi', 'trong', 'ngoai', 'tren', 'duoi',
            'khi', 'neu', 'thi', 'cho', 'den', 'tai', 'ban', 'cac', 'mot', 'hai',
            'la', 'co', 'khong', 'duoc', 'tim', 'hoc', 'sinh', 'giao', 'vien'
        }
        keywords = {w for w in words if w not in stop_words and len(w) >= 3}
        return frozenset(keywords)

    def quick_coverage_assessment(self, request: str, subtopics: List[str], chunks: List) -> tuple:
        """üöÄ Fast heuristic assessment tr∆∞·ªõc khi g·ªçi LLM."""
        if not chunks:
            return False, 0.0, "no_chunks"

        # 1) Keywords y√™u c·∫ßu
        request_keywords = self.extract_keywords(request or "")
        topic_keywords: Set[str] = set()
        for t in (subtopics or []):
            topic_keywords.update(self.extract_keywords(t or ""))
        required_keywords = request_keywords | topic_keywords

        # 2) T·ª´ kho√° bao ph·ªß + th·ªëng k√™
        covered_keywords: Set[str] = set()
        total_content_length = 0
        sources = set()
        high_score_chunks = 0

        for ch in chunks:
            content = getattr(ch, 'content', None)
            if content is None:
                content = ch.get('content', '')
            score = getattr(ch, 'score', None)
            if score is None:
                score = ch.get('score', 0)
            source = getattr(ch, 'source_file', None)
            if source is None:
                source = ch.get('source_file', '')

            if content:
                covered_keywords.update(self.extract_keywords(content))
                total_content_length += len(content)

            if source:
                sources.add(source)
            if (score or 0) > 0.7:
                high_score_chunks += 1

        # 3) T√≠nh ƒëi·ªÉm
        keyword_coverage = len(covered_keywords & required_keywords) / max(len(required_keywords), 1)
        length_score = min(total_content_length / 5000, 1.0)         # 5k chars = good
        source_diversity = min(len(sources) / 3, 1.0)                # 3+ ngu·ªìn = t·ªët
        quality_score = min(high_score_chunks / max(len(chunks), 1), 1.0)

        composite_score = (
            keyword_coverage * self.keyword_weight +
            length_score * self.length_weight +
            source_diversity * self.source_diversity_weight +
            quality_score * self.quality_weight
        )

        # 4) Quy·∫øt ƒë·ªãnh nhanh
        if composite_score >= self.high_confidence_threshold:
            decision, reason = True, "high_confidence_heuristic"
        elif composite_score <= self.low_confidence_threshold:
            decision, reason = False, "low_confidence_heuristic"
        else:
            decision, reason = None, "uncertain_need_llm"

        self.logger.debug(
            "DBG fast: req_kw=%d, cov_kw=%d, kw_cov=%.3f, len=%d, src=%d, hi=%.3f, comp=%.3f",
            len(required_keywords), len(covered_keywords), keyword_coverage,
            total_content_length, len(sources), quality_score, composite_score
        )
        return decision, composite_score, reason

    def optimize_content_fast(self, chunks: List, target_length: int = None) -> str:
        """üöÄ Chu·∫©n b·ªã content t·ªëi ∆∞u, ∆∞u ti√™n ƒëa d·∫°ng ngu·ªìn (early stop)."""
        if not chunks:
            return ""

        target_length = target_length or self.max_content_length
        sorted_chunks = sorted(
            chunks,
            key=lambda x: getattr(x, 'score', 0) if hasattr(x, 'score') else x.get('score', 0),
            reverse=True
        )

        content_parts: List[str] = []
        total_length = 0
        sources_seen = set()

        for ch in sorted_chunks:
            content = getattr(ch, 'content', None)
            if content is None:
                content = ch.get('content', '')
            source = getattr(ch, 'source_file', None)
            if source is None:
                source = ch.get('source_file', 'Unknown')

            if not content:
                continue

            is_new_source = source not in sources_seen
            source_bonus = 200 if is_new_source else 0  # ∆∞u ti√™n ngu·ªìn m·ªõi

            text_snippet = f"[Ngu·ªìn: {source}] {content}"
            effective_len = max(0, len(text_snippet) - source_bonus)

            if total_length + effective_len <= target_length:
                content_parts.append(text_snippet)
                total_length += effective_len
                sources_seen.add(source)
            else:
                remaining = target_length - total_length - 50  # buffer
                if remaining > 200:
                    truncated = content[:remaining] + "..."
                    content_parts.append(f"[Ngu·ªìn: {source}] {truncated}")
                break

        return "\n\n".join(content_parts)

    def run(self, request: str, subtopics: List[str], chunks: List) -> CoverageAssessment:
        """üöÄ OPTIMIZED coverage evaluation v·ªõi fast path."""
        heuristic_score = 0.0  # lu√¥n gi·ªØ ƒë·ªÉ fallback c√≥ ƒëi·ªÉm n·ªÅn
        try:
            quick_decision, heuristic_score, reason = self.quick_coverage_assessment(request, subtopics, chunks)

            if quick_decision is not None:
                self.fast_decisions += 1
                if quick_decision:
                    level = self._score_to_level(heuristic_score)
                    self.logger.info(
                        f"‚úÖ Fast decision: {getattr(level,'name',level)}/{getattr(level,'value','')} "
                        f"(score={heuristic_score:.2f}, reason={reason})"
                    )
                    return CoverageAssessment(
                        level=level,
                        score=heuristic_score,
                        missing_topics=[],
                        covered_topics=subtopics,
                    )
                else:
                    level = CoverageLevel.INSUFFICIENT
                    self.logger.info(
                        f"‚ùå Fast decision: {level.name}/{level.value} "
                        f"(score={heuristic_score:.2f}, reason={reason})"
                    )
                    return CoverageAssessment(
                        level=level,
                        score=heuristic_score,
                        missing_topics=subtopics,
                        covered_topics=[],
                    )

            # Uncertain ‚Üí g·ªçi LLM
            self.llm_calls += 1
            self.logger.info(f"ü§î Uncertain case, using LLM (heuristic_score={heuristic_score:.2f})")

            content = self.optimize_content_fast(chunks)
            if not content.strip():
                self.logger.warning("No valid content for LLM assessment")
                return CoverageAssessment(
                    level=CoverageLevel.INSUFFICIENT,
                    score=heuristic_score,
                    missing_topics=subtopics,
                    covered_topics=[],
                )

            prompt = self.prompt.format(
                request=request,
                required_topics=", ".join(subtopics or []),
                content=content
            )
            messages = [{"role": "user", "content": prompt}]
            result = self.llm.chat(messages, temperature=0.2, max_tokens=1500)

            parsed_result = self._parse_llm_response(result, subtopics, heuristic_score)
            self.logger.info(
                f"üß† LLM decision: {getattr(parsed_result.level,'name',parsed_result.level)}/"
                f"{getattr(parsed_result.level,'value','')} (score={parsed_result.score:.2f})"
            )
            return parsed_result

        except Exception as e:
            self.logger.error(f"Coverage evaluation error: {e}")
            return self._fallback_assessment(subtopics, heuristic_score)

    # -----------------------------
    # Helpers / parsing / mapping
    # -----------------------------
    def _parse_llm_response(self, result: Any, subtopics: List[str], heuristic_score: float) -> CoverageAssessment:
        """Parse LLM response an to√†n, map level v·ªÅ Enum h·ª£p l·ªá, blend ƒëi·ªÉm."""
        try:
            # 1) Chu·∫©n ho√° result ‚Üí string JSON
            if isinstance(result, dict):
                if "choices" in result:  # OpenAI-style
                    result = result["choices"][0]["message"]["content"]
                elif "content" in result:
                    result = result["content"]
                else:
                    result = json.dumps(result)
            elif isinstance(result, list):
                result = json.dumps(result)
            elif not isinstance(result, str):
                result = str(result)

            # 2) ∆Øu ti√™n l·∫•y n·ªôi dung trong fenced code ```json ... ```
            m = re.search(r"```json\s*(\{.*?\})\s*```", result, flags=re.S | re.I)
            if m:
                result = m.group(1)
            else:
                # fallback: l·∫•y object ƒë·∫ßu ti√™n
                m2 = re.search(r"\{.*?\}", result, flags=re.S)
                if m2:
                    result = m2.group(0)

            parsed = json.loads(result)

            # 3) Map level ‚Üí Enum (ch·∫•p nh·∫≠n h·ªá kh√°c)
            level_str = str(parsed.get("level", "")).strip()
            level = self._to_enum_level(level_str)

            # 4) Blend ƒëi·ªÉm
            llm_score_raw = parsed.get("score", None)
            try:
                llm_score = float(llm_score_raw) if llm_score_raw is not None else heuristic_score
            except Exception:
                llm_score = heuristic_score

            final_score = 0.7 * llm_score + 0.3 * heuristic_score

            return CoverageAssessment(
                level=level,
                score=final_score,
                missing_topics=self._clean_topic_list(parsed.get("missing_topics", [])),
                covered_topics=self._clean_topic_list(parsed.get("covered_topics", []))
            )

        except json.JSONDecodeError as e:
            self.logger.warning(f"JSON parse error: {e}")
            return self._fallback_assessment(subtopics, heuristic_score)
        except Exception as e:
            self.logger.error(f"Error parsing LLM response: {e}")
            return self._fallback_assessment(subtopics, heuristic_score)

    def _clean_topic_list(self, topics: List) -> List[str]:
        """L√†m s·∫°ch danh s√°ch topics."""
        if not isinstance(topics, list):
            return []
        cleaned: List[str] = []
        for t in topics:
            if isinstance(t, str):
                s = t.strip().strip('",‚Ä¢').replace('",', '')
                if s:
                    cleaned.append(s)
        return cleaned

    def _to_enum_level(self, raw: str) -> CoverageLevel:
        """
        Map chu·ªói level sang CoverageLevel theo h·ªá INSUFFICIENT/PARTIAL/ADEQUATE/COMPREHENSIVE.
        Ch·∫•p nh·∫≠n c·∫£ h·ªá developing/good/excellent/outstanding v√† quy v·ªÅ h·ªá c·ªßa b·∫°n.
        """
        v = (raw or "").strip().lower()

        synonyms = {
            # H·ªá c·ªßa b·∫°n
            "insufficient": "insufficient",
            "partial": "partial",
            "adequate": "adequate",
            "comprehensive": "comprehensive",
            # H·ªá 4 m·ª©c kh√°c
            "developing": "partial",
            "good": "adequate",
            "excellent": "comprehensive",
            "outstanding": "comprehensive",
        }
        key = synonyms.get(v, v)

        # Match theo value tr∆∞·ªõc r·ªìi ƒë·∫øn name
        for e in CoverageLevel:
            if str(getattr(e, "value", "")).lower() == key:
                return e
        for e in CoverageLevel:
            if str(getattr(e, "name", "")).lower() == key:
                return e

        # Fallback an to√†n
        return CoverageLevel.INSUFFICIENT

    def _score_to_level(self, score: float) -> CoverageLevel:
        """Convert numeric score ‚Üí CoverageLevel theo h·ªá c·ªßa b·∫°n."""
        if score >= 0.9:
            return CoverageLevel.COMPREHENSIVE
        elif score >= 0.7:
            return CoverageLevel.ADEQUATE
        elif score >= 0.4:
            return CoverageLevel.PARTIAL
        else:
            return CoverageLevel.INSUFFICIENT

    def _fallback_assessment(self, subtopics: List[str], score: float = 0.0) -> CoverageAssessment:
        """Fallback assessment khi LLM/parse th·∫•t b·∫°i (gi·ªØ heuristic score n·∫øu c√≥)."""
        return CoverageAssessment(
            level=CoverageLevel.INSUFFICIENT,
            score=score,
            missing_topics=subtopics,
            covered_topics=[],
        )

    # -----------------------------
    # Stats & config
    # -----------------------------
    def get_performance_stats(self) -> Dict[str, Any]:
        """Get performance statistics."""
        total_calls = self.fast_decisions + self.llm_calls
        fast_decision_rate = self.fast_decisions / total_calls if total_calls > 0 else 0
        return {
            "total_evaluations": total_calls,
            "fast_decisions": self.fast_decisions,
            "llm_calls": self.llm_calls,
            "fast_decision_rate": fast_decision_rate,
            "avg_speedup": f"{(1 - fast_decision_rate) * 100:.1f}% calls avoided LLM"
        }

    def reset_stats(self):
        """Reset performance counters."""
        self.fast_decisions = 0
        self.llm_calls = 0

    def configure_thresholds(self, high_confidence: float = None, low_confidence: float = None):
        """Tune ng∆∞·ª°ng quy·∫øt ƒë·ªãnh fast path."""
        if high_confidence is not None:
            self.high_confidence_threshold = high_confidence
        if low_confidence is not None:
            self.low_confidence_threshold = low_confidence
        self.logger.info(f"Thresholds updated: high={self.high_confidence_threshold}, low={self.low_confidence_threshold}")
