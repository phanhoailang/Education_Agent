import sys
import os
import json
import datetime
from pathlib import Path
from langgraph.graph import StateGraph, END
from typing import TypedDict, Dict, Any, Optional, List
from bson import ObjectId
from dotenv import load_dotenv

from utils.GPTClient import GPTClient
from utils.GeminiClient import GeminiClient
from modules.agents.ChatAgent import ChatAgent
from modules.agents.SubtopicGeneratorAgent import SubtopicGeneratorAgent
from modules.rag_module.SemanticChunkFilter import SemanticChunkFilter
from modules.rag_module.documents_processing.main_processor import EduMateDocumentProcessor
from modules.rag_module.data_chunking.processor import IntelligentVietnameseChunkingProcessor
from modules.rag_module.data_embedding.embedding_processor import VietnameseEmbeddingProcessor
from modules.rag_module.query_db.MongoDBClient import MongoDBClient
from modules.rag_module.DeepRetrieval import OptimizedDeepRetrieval, DeepRetrieval

# Fix import issue - sá»­ dá»¥ng tÃªn class nháº¥t quÃ¡n
try:
    from modules.lesson_plan.LessonPlanPipeline import LessonPlanPipeline
except ImportError:
    try:
        from modules.lesson_plan.LessonPlanPipeline import LessonPlanPipeline as LessonPlanPipeline
    except ImportError:
        raise ImportError("Could not import LessonPlanPipeline or LessonPipeline from modules.lesson_plan.LessonPlanPipeline")

from modules.quiz_plan.QuizPipeline import QuizPipeline
from modules.slide_plan.SlidePipeline import SlidePipeline

load_dotenv()

# ========================= Helpers =========================
def clean_objectid(obj):
    if isinstance(obj, dict):
        return {k: clean_objectid(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [clean_objectid(i) for i in obj]
    elif isinstance(obj, ObjectId):
        return str(obj)
    else:
        return obj


def _build_user_prompt(form_data: Dict[str, Any]) -> str:
    """Táº¡o prompt tá»« form data"""
    
    parts = []
    
    # ThÃ´ng tin cÆ¡ báº£n
    if form_data.get("subject"):
        parts.append(f"MÃ´n há»c: {form_data['subject']}")
    if form_data.get("grade"):
        parts.append(f"Lá»›p: {form_data['grade']}")
    if form_data.get("topic"):
        parts.append(f"Chá»§ Ä‘á»: {form_data['topic']}")
    if form_data.get("duration"):
        parts.append(f"Thá»i lÆ°á»£ng: {form_data['duration']} phÃºt")
    
    # YÃªu cáº§u bá»• sung
    if form_data.get("additional_requirements"):
        parts.append(f"YÃªu cáº§u: {form_data['additional_requirements']}")
        
    # Phong cÃ¡ch vÃ  Ä‘á»™ khÃ³
    if form_data.get("teaching_style"):
        parts.append(f"Phong cÃ¡ch: {form_data['teaching_style']}")
    if form_data.get("difficulty"):
        parts.append(f"Äá»™ khÃ³: {form_data['difficulty']}")
    if form_data.get("textbook"):
        parts.append(f"SÃ¡ch giÃ¡o khoa: {form_data['textbook']}")
    
    return "\n".join(parts) if parts else "Táº¡o ná»™i dung giÃ¡o dá»¥c"


# ========================= State =========================
class FlowState(TypedDict):
    form_data: dict
    user_prompt: str
    subtopics: list
    db_chunks: list
    uploaded_chunks: list
    search_chunks: list
    all_chunks: list
    embedded_chunks: list
    filtered_chunks: list
    lesson_plan: dict
    quiz: dict
    slide_plan: dict  # ThÃªm slide_plan
    output_path: str
    __skip__: bool
    __plan_done__: bool
    __quiz_done__: bool
    __slide_done__: bool # ThÃªm cá» __slide_done__


# ========================= Enhanced FlowState Class =========================
class EnhancedFlowState:
    """
    State object Ä‘á»ƒ truyá»n dá»¯ liá»‡u giá»¯a cÃ¡c pipeline
    TÆ°Æ¡ng thÃ­ch vá»›i langgraph náº¿u cáº§n má»Ÿ rá»™ng
    """
    def __init__(self, initial_data: Optional[Dict[str, Any]] = None):
        self._data = initial_data or {}
    
    def get(self, key: str, default=None):
        return self._data.get(key, default)
    
    def update(self, data: Dict[str, Any]):
        self._data.update(data)
    
    def __getitem__(self, key):
        return self._data[key]
    
    def __setitem__(self, key, value):
        self._data[key] = value
    
    def __contains__(self, key):
        return key in self._data
    
    def keys(self):
        return self._data.keys()
    
    def items(self):
        return self._data.items()
    
    def to_dict(self):
        return self._data.copy()


# ========================= Alternative Simple Flow =========================
def run_simple_flow(form_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Flow Ä‘Æ¡n giáº£n xá»­ lÃ½ táº¡o ná»™i dung giÃ¡o dá»¥c (khÃ´ng dÃ¹ng langgraph)
    
    Args:
        form_data: Dá»¯ liá»‡u tá»« form ngÆ°á»i dÃ¹ng
        
    Returns:
        Dict chá»©a káº¿t quáº£ cÃ¡c pipeline
    """
    print("ğŸš€ [SIMPLE_FLOW] Starting education content generation flow...")
    print(f"ğŸ“‹ [SIMPLE_FLOW] Form data: {form_data}")
    
    # Khá»Ÿi táº¡o state
    state = {
        "form_data": form_data,
        "user_prompt": _build_user_prompt(form_data),
        "filtered_chunks": [],  # CÃ³ thá»ƒ xá»­ lÃ½ files á»Ÿ Ä‘Ã¢y náº¿u cáº§n
    }
    
    content_types = form_data.get("content_types", [])
    print(f"ğŸ¯ [SIMPLE_FLOW] Requested content types: {content_types}")
    
    # Khá»Ÿi táº¡o LLM client
    try:
        llm = GPTClient(
            api_key=os.environ.get("AZURE_API_KEY"),
            endpoint=os.environ.get("AZURE_ENDPOINT"),
            model=os.environ.get("AZURE_MODEL"),
            api_version=os.environ.get("AZURE_API_VERSION")
        )
        print("âœ… [SIMPLE_FLOW] LLM client initialized")
    except Exception as e:
        print(f"âŒ [SIMPLE_FLOW] Failed to initialize LLM: {e}")
        return {"error": f"Failed to initialize LLM: {e}"}
    
    # ====== LESSON PLAN ======
    if "lesson_plan" in content_types:
        print("\nğŸ“š [SIMPLE_FLOW] Processing lesson plan...")
        try:
            from modules.lesson_plan.LessonPlanPipeline import LessonPlanPipeline
            lesson_pipeline = LessonPlanPipeline(llm)
            lesson_result = lesson_pipeline(state)
            state.update(lesson_result)
            print("âœ… [SIMPLE_FLOW] Lesson plan completed")
        except Exception as e:
            print(f"âŒ [SIMPLE_FLOW] Lesson plan failed: {e}")
            state["lesson_plan"] = {"error": str(e)}
    
    # ====== QUIZ ======
    if "quiz" in content_types:
        print("\nğŸ§ª [SIMPLE_FLOW] Processing quiz...")
        try:
            quiz_pipeline = QuizPipeline(llm)
            
            # Táº¡o state phÃ¹ há»£p cho quiz pipeline
            quiz_state = state.copy()
            quiz_state.update({
                "quiz_source": form_data.get("quiz_source", "material"),
                "quiz_config": form_data.get("quiz_config", {}),
            })
            
            quiz_result = quiz_pipeline(quiz_state)
            state.update(quiz_result)
            print("âœ… [SIMPLE_FLOW] Quiz completed")
        except Exception as e:
            print(f"âŒ [SIMPLE_FLOW] Quiz failed: {e}")
            state["quiz"] = {"error": str(e)}
    
    # ====== SLIDE PLAN ======
    if "slide_plan" in content_types:
        print("\nğŸ¬ [SIMPLE_FLOW] Processing slide plan...")
        try:
            slide_pipeline = SlidePipeline(llm)
            
            # Táº¡o state phÃ¹ há»£p cho slide pipeline  
            slide_state = state.copy()
            slide_state.update({
                "slide_config": form_data.get("slide_config", {}),
            })
            
            slide_result = slide_pipeline(slide_state)
            state.update(slide_result)
            print("âœ… [SIMPLE_FLOW] Slide plan completed")
        except Exception as e:
            print(f"âŒ [SIMPLE_FLOW] Slide plan failed: {e}")
            state["slide_plan"] = {"error": str(e)}
    
    print("ğŸ [SIMPLE_FLOW] Flow completed successfully")
    return state


# ========================= Slide Plan Node =========================
class SlidePlanNode:
    """Node xá»­ lÃ½ slide plan trong flow"""
    
    def __init__(self, llm: GPTClient):
        self.pipeline = SlidePipeline(llm)
    
    def __call__(self, state: EnhancedFlowState) -> Dict[str, Any]:
        """Execute slide plan generation"""
        print("\nğŸ¬ Starting Slide Plan generation...")
        
        form = state.get("form_data", {})
        content_types = form.get("content_types", [])
        
        if "slide_plan" not in content_types:
            print("â­ Skip slide plan (not requested)")
            return {"slide_plan": {}, "__slide_done__": True}
        
        try:
            # Get lesson plan if available for slide generation
            lesson_plan = state.get("lesson_plan", {})
            
            if not lesson_plan:
                print("âš ï¸ No lesson plan available for slide generation")
                return {
                    "slide_plan": {"error": "No lesson plan available for slide generation"}, 
                    "__slide_done__": True
                }
            
            # Use the pipeline's __call__ method
            slide_result = self.pipeline(state)
            
            print("âœ… Slide Plan generation completed!")
            return slide_result
            
        except Exception as e:
            error_msg = f"Error in slide plan generation: {str(e)}"
            print(f"âŒ {error_msg}")
            return {
                "slide_plan": {"error": error_msg}, 
                "__slide_done__": True
            }


# ========================= Standalone Slide Creator =========================
def create_slide_plan_standalone(
    lesson_plan_content: str,
    slide_config: Optional[Dict[str, Any]] = None,
    llm: Optional[GPTClient] = None
) -> Dict[str, Any]:
    """
    Táº¡o slide plan tá»« lesson plan content
    
    Args:
        lesson_plan_content: Ná»™i dung lesson plan (JSON string hoáº·c markdown)
        slide_config: Cáº¥u hÃ¬nh cho slide
        llm: LLM client (táº¡o má»›i náº¿u khÃ´ng cÃ³)
        
    Returns:
        Dict chá»©a káº¿t quáº£ slide plan
    """
    try:
        if llm is None:
            llm = GPTClient(
                api_key=os.environ.get("AZURE_API_KEY"),
                endpoint=os.environ.get("AZURE_ENDPOINT"),
                model=os.environ.get("AZURE_MODEL"),
                api_version=os.environ.get("AZURE_API_VERSION")
            )
        
        slide_pipeline = SlidePipeline(llm)
        
        # Parse lesson plan náº¿u lÃ  string
        if isinstance(lesson_plan_content, str):
            try:
                lesson_plan = json.loads(lesson_plan_content)
            except json.JSONDecodeError:
                # Náº¿u khÃ´ng pháº£i JSON, coi nhÆ° markdown content
                lesson_plan = {"complete_markdown": lesson_plan_content}
        else:
            lesson_plan = lesson_plan_content
        
        # Táº¡o mock state
        mock_state = EnhancedFlowState({
            "lesson_plan": lesson_plan,
            "form_data": {"slide_config": slide_config or {}},
        })
        
        return slide_pipeline(mock_state)
        
    except Exception as e:
        return {"slide_plan": {"error": str(e)}}


# ========================= Nodes =========================
class PromptGenerator:
    def __init__(self, llm: GPTClient):
        self.agent = ChatAgent(llm)

    def __call__(self, state: FlowState):
        result = self.agent.run(mode="generate_prompt", form_data=state["form_data"])
        print("\nğŸ§  Prompt gá»‘c sinh tá»« form:")
        print(result)
        return {"user_prompt": result}


class SubtopicGenerator:
    def __init__(self, llm: GPTClient):
        self.agent = SubtopicGeneratorAgent(llm)

    def __call__(self, state: FlowState):
        prompt = state["user_prompt"]
        subtopics = self.agent.run(prompt)
        print(f"\nğŸ“Œ ÄÃ£ sinh {len(subtopics)} subtopics:")
        for i, topic in enumerate(subtopics, 1):
            print(f"   {i}. {topic}")
        return {"subtopics": subtopics}


class FileProcessor:
    def __init__(self):
        self.document_processor = EduMateDocumentProcessor.create_balanced()
        self.chunking_processor = IntelligentVietnameseChunkingProcessor(
            output_dir="temp_langgraph_chunking",
            min_quality=0.65
        )

    def __call__(self, state: FlowState):
        form = state["form_data"]
        files = form.get("files", [])
        if not files:
            print("\nKhÃ´ng cÃ³ file Ä‘Ã­nh kÃ¨m. Sáº½ gá»i agent truy váº¥n sau...")
            return {"__skip__": True, "search_chunks": [], "db_chunks": [], "all_chunks": []}

        all_standardized_chunks = []

        for file_path in files:
            print(f"\nğŸ“‚ Äang xá»­ lÃ½ file: {file_path}")
            try:
                file_path_obj = Path(file_path)

                # 1) Document processing
                doc_result = self.document_processor.process_file(file_path_obj)
                if not doc_result.success:
                    print(f"Document processing failed: {doc_result.error_message}")
                    continue

                # 2) Chunking (trÃªn file .md táº¡m)
                import tempfile
                with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False, encoding='utf-8') as temp_file:
                    temp_file.write(doc_result.content)
                    temp_md_path = temp_file.name

                chunking_result = self.chunking_processor.run(
                    Path(temp_md_path),
                    strategy=None,
                    save_json=False,
                    print_report=False
                )
                chunks_data = chunking_result['result']['chunking_results']['chunks_data']

                # 3) Standardize
                for i, chunk_data in enumerate(chunks_data):
                    all_standardized_chunks.append({
                        "chunk_id": f"{Path(file_path).stem}_chunk_{i+1:02d}",
                        "content": chunk_data["content"],
                        "token_count": chunk_data.get("word_count", 0),
                        "method": chunk_data.get("chunking_strategy", "intelligent"),
                        "source_file": file_path,
                        "retrieved_from": "upload",
                        "char_count": chunk_data.get("char_count", 0),
                        "keywords": chunk_data.get("keywords", []),
                        "coherence_score": chunk_data.get("semantic_coherence_score", 0.0),
                        "completeness_score": chunk_data.get("completeness_score", 0.0),
                        "language_confidence": chunk_data.get("language_confidence", 0.0)
                    })

                print(f"âœ… Processed {file_path}: {len(chunks_data)} chunks created")

                try:
                    os.unlink(temp_md_path)
                except Exception:
                    pass

            except Exception as e:
                print(f"âš ï¸ Failed to process {file_path}: {e}")
                continue

        if not all_standardized_chunks:
            print("\nâŒ› KhÃ´ng cÃ³ file nÃ o Ä‘Æ°á»£c xá»­ lÃ½ thÃ nh cÃ´ng")
            return {"__skip__": True, "search_chunks": [], "db_chunks": [], "all_chunks": []}

        print(f"\nğŸ‰ Tá»•ng cá»™ng Ä‘Ã£ xá»­ lÃ½: {len(all_standardized_chunks)} chunks tá»« {len(files)} files")
        return {
            "search_chunks": [],
            "db_chunks": [],
            "uploaded_chunks": all_standardized_chunks,
            "__skip__": False,
            "source_files": files,
            "processing_method": "new_intelligent",
        }


class AgentBasedRetrieval:
    def __init__(self):
        self.retriever = OptimizedDeepRetrieval()

    def __call__(self, state: FlowState):
        print("ğŸ§  [agent_retrieval] ÄANG ÄÆ¯á»¢C Gá»ŒI")
        prompt = state.get("user_prompt", "")
        subtopics = state.get("subtopics", [])
        if not prompt or not subtopics:
            print("\nThiáº¿u prompt hoáº·c subtopics.")
            return {}

        chunks = self.retriever.retrieve(prompt, subtopics)
        db_chunks = [c for c in chunks if c.get("retrieved_from") == "db"]
        search_chunks = [c for c in chunks if c.get("retrieved_from") == "search"]
        all_chunks = db_chunks + search_chunks

        print(f"\nğŸ“¦ Tá»•ng cá»™ng: {len(all_chunks)} chunks (DB: {len(db_chunks)}, Search: {len(search_chunks)})")
        return {"db_chunks": db_chunks, "search_chunks": search_chunks, "all_chunks": all_chunks}


class EmbedAndStoreUploaded:
    def __call__(self, state: FlowState):
        chunks = state.get("uploaded_chunks", [])
        if not chunks:
            print("\nâŒ KhÃ´ng cÃ³ chunks Ä‘á»ƒ embedding (uploaded).")
            return {}
        
        # Láº¥y source files tá»« state
        source_files = state.get("source_files", ["upload"])
        result = embed_and_store_chunks(chunks, source_files)
        
        # Debug log
        print(f"ğŸ” [EmbedAndStoreUploaded] Returned keys: {list(result.keys())}")
        
        return result


class EmbedAndStoreSearched:
    def __call__(self, state: FlowState):
        chunks = state.get("search_chunks", [])
        if not chunks:
            print("\nâŒ KhÃ´ng cÃ³ chunks Ä‘á»ƒ embedding (searched).")
            return {}
        
        result = embed_and_store_chunks(chunks, "web_search")
        
        # Debug log  
        print(f"ğŸ” [EmbedAndStoreSearched] Returned keys: {list(result.keys())}")
        
        return result


def embed_and_store_chunks(chunks, source_files):
    print("\nğŸ“„ Chunks:")
    print(json.dumps(chunks[:3], ensure_ascii=False, indent=2))
    if len(chunks) > 3:
        print(f"... (cÃ²n {len(chunks) - 3} chunks ná»¯a)\n")

    chunks_with_metadata = []
    for chunk in chunks:
        if "metadata" not in chunk:
            chunk["metadata"] = {}
        chunk["metadata"]["source_file"] = chunk.get("source_file", "unknown")
        chunk["metadata"]["all_source_files"] = source_files if isinstance(source_files, list) else [source_files]
        chunk["metadata"]["collection"] = "lectures"
        chunks_with_metadata.append(chunk)

    os.makedirs("temp_embedding", exist_ok=True)
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    temp_path = os.path.join("temp_embedding", f"temp_chunks_{timestamp}.json")

    with open(temp_path, "w", encoding="utf-8") as f:
        json.dump(chunks_with_metadata, f, ensure_ascii=False, indent=2)

    embedder = VietnameseEmbeddingProcessor()
    result = embedder.run(temp_path, save_results=False)
    embedded_chunks = result["chunks"]

    try:
        os.remove(temp_path)
    except Exception:
        pass

    db = MongoDBClient()
    db.insert_many("lectures", embedded_chunks)
    print(f"\nâœ… ÄÃ£ lÆ°u {len(embedded_chunks)} chunks vÃ o MongoDB")

    os.makedirs("output_chunks", exist_ok=True)
    out_path = os.path.join("output_chunks", f"chunks_{timestamp}.json")
    cleaned = clean_objectid(embedded_chunks)
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(cleaned, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“¦ ÄÃ£ lÆ°u vÃ o: {out_path}")
    
    # ===== FIX: Sá»¬ Dá»¤NG KEY RIÃŠNG CHO CHUNKS =====
    return {
        "embedded_chunks": embedded_chunks,
        "chunks_output_path": out_path,  # Key riÃªng cho chunks, khÃ´ng pháº£i output_path chung
    }


class FilterChunks:
    def __init__(self):
        self.engine = SemanticChunkFilter()

    def __call__(self, state: FlowState):
        uploaded_chunks = state.get("uploaded_chunks", [])
        all_chunks = state.get("all_chunks", [])
        subtopics = state.get("subtopics", [])

        if uploaded_chunks:
            chunks = uploaded_chunks
            print(f"\nğŸ“‚ Lá»c {len(chunks)} uploaded chunks theo {len(subtopics)} subtopics...")
        else:
            chunks = all_chunks
            print(f"\nğŸŒ Lá»c {len(chunks)} (db + search) chunks theo {len(subtopics)} subtopics...")

        if not chunks or not subtopics:
            print("\nâš ï¸ KhÃ´ng cÃ³ chunks hoáº·c subtopics Ä‘á»ƒ lá»c")
            return {"filtered_chunks": chunks}

        if len(chunks) <= 5:
            print(f"\nâ„¹ï¸ Chá»‰ cÃ³ {len(chunks)} chunks â€“ bá» qua bÆ°á»›c lá»c semantic.")
            return {"filtered_chunks": chunks}

        filtered = self.engine.filter(chunks, subtopics)
        print(f"âœ… ÄÃ£ lá»c cÃ²n {len(filtered)} chunks liÃªn quan")
        return {"filtered_chunks": filtered}


class GenerateLessonPlan:
    def __init__(self, llm: GPTClient):
        self.pipeline = LessonPlanPipeline(llm)

    def __call__(self, state: FlowState):
        # Kiá»ƒm tra cÃ³ cáº§n táº¡o lesson plan khÃ´ng
        if not should_generate_lesson_plan(state):
            print("â­ Skip táº¡o Lesson Plan (user khÃ´ng tick)")
            return {"lesson_plan": {}, "__plan_done__": True}
        print("\nğŸ“ Báº¯t Ä‘áº§u táº¡o káº¿ hoáº¡ch bÃ i giáº£ng...")
        prompt = state.get("user_prompt", "")
        filtered_chunks = state.get("filtered_chunks", [])
        if not prompt:
            return {"lesson_plan": {"error": "KhÃ´ng cÃ³ prompt Ä‘á»ƒ táº¡o bÃ i giáº£ng"}, "__plan_done__": True}
        lesson_plan = self.pipeline.create_full_lesson_plan(prompt, filtered_chunks)
        print("âœ… HoÃ n thÃ nh táº¡o káº¿ hoáº¡ch bÃ i giáº£ng!")
        if "output_path" in lesson_plan:
            print(f"ğŸ“ ÄÃ£ lÆ°u táº¡i: {lesson_plan['output_path']}")
        return {"lesson_plan": lesson_plan, "__plan_done__": True}


class GenerateQuiz:
    def __init__(self, llm: GPTClient):
        self.pipeline = QuizPipeline(llm)

    def __call__(self, state: FlowState):
        # Kiá»ƒm tra cÃ³ cáº§n táº¡o quiz khÃ´ng
        if not should_generate_quiz(state):
            print("â­ Skip táº¡o Quiz (user khÃ´ng tick)")
            return {"quiz": {}, "__quiz_done__": True}
        
        print("\nğŸ§ª Báº¯t Ä‘áº§u táº¡o Quiz...")
        form = state.get("form_data", {}) or {}
        mode = form.get("quiz_source", "material")  # "material" | "plan"
        config = form.get("quiz_config", {})
        prompt = state.get("user_prompt", "")
        filtered_chunks = state.get("filtered_chunks", [])
        lesson_plan = state.get("lesson_plan", {})

        if mode == "plan" and not lesson_plan:
            print("âš ï¸ KhÃ´ng cÃ³ lesson plan Ä‘á»ƒ sinh quiz. Fallback sang material.")
            mode = "material"

        # --- Gá»i pipeline vá»›i fallback ---
        if mode == "plan":
            if hasattr(self.pipeline, "from_lesson_plan"):
                quiz = self.pipeline.from_lesson_plan(lesson_plan, prompt, config)
            else:
                # Fallback: fuse lesson plan vÃ o prompt rá»“i táº¡o quiz tá»« chunks
                plan_md = (
                    lesson_plan.get("complete_markdown")
                    or lesson_plan.get("markdown", "")
                    or json.dumps(lesson_plan, ensure_ascii=False)
                )
                augmented_prompt = f"{prompt}\n\n[LESSON_PLAN]\n{plan_md}"
                quiz = self.pipeline.create_full_quiz(augmented_prompt, filtered_chunks)
        else:
            if hasattr(self.pipeline, "from_materials"):
                quiz = self.pipeline.from_materials(prompt, filtered_chunks, config)
            else:
                quiz = self.pipeline.create_full_quiz(prompt, filtered_chunks)

        print("âœ… HoÃ n thÃ nh táº¡o Quiz!")

        # ===== FIX: KHÃ”NG GHI ÄÃˆ output_path =====
        # Giá»¯ nguyÃªn output_path tá»« embed_store náº¿u cÃ³
        result = {"quiz": quiz, "__quiz_done__": True}
        
        # Chá»‰ cáº­p nháº­t quiz_output_path riÃªng, khÃ´ng ghi Ä‘Ã¨ output_path
        if isinstance(quiz, dict) and "output_path" in quiz:
            print(f"ğŸ“ Quiz Ä‘Ã£ lÆ°u táº¡i: {quiz['output_path']}")
            result["quiz_output_path"] = quiz["output_path"]  # LÆ°u riÃªng
            
            # Debug: In ra Ä‘á»ƒ check
            print(f"ğŸ” [DEBUG] Quiz output_path: {quiz['output_path']}")
            print(f"ğŸ” [DEBUG] Current state output_path: {state.get('output_path', 'N/A')}")

        return result


class GenerateSlidePlan:
    def __init__(self, llm: GPTClient):
        self.pipeline = SlidePipeline(llm)

    def __call__(self, state: FlowState):
        # Kiá»ƒm tra cÃ³ cáº§n táº¡o slide plan khÃ´ng
        if not should_generate_slide_plan(state):
            print("â­ Skip táº¡o Slide Plan (user khÃ´ng tick)")
            return {"slide_plan": {}, "__slide_done__": True}

        print("\nğŸ“Š Báº¯t Ä‘áº§u táº¡o Slide Plan...")
        prompt = state.get("user_prompt", "")
        lesson_plan = state.get("lesson_plan", {})

        if not prompt:
            return {"slide_plan": {"error": "KhÃ´ng cÃ³ prompt Ä‘á»ƒ táº¡o slide"}, "__slide_done__": True}

        # Kiá»ƒm tra lesson_plan cÃ³ ná»™i dung khÃ´ng
        if not lesson_plan or not (lesson_plan.get("complete_markdown") or lesson_plan.get("markdown")):
            print("âš ï¸  KhÃ´ng cÃ³ ná»™i dung Káº¿ hoáº¡ch bÃ i giáº£ng há»£p lá»‡ Ä‘á»ƒ táº¡o slide.")
            return {"slide_plan": {"error": "Cáº§n cÃ³ Káº¿ hoáº¡ch bÃ i giáº£ng trÆ°á»›c"}, "__slide_done__": True}

        lesson_plan_content = (
            lesson_plan.get("complete_markdown", "")
            or lesson_plan.get("markdown", "")
        )

        form = state.get("form_data", {}) or {}
        slide_config = form.get("slide_config", {}) or {
            "color_scheme": "blue",
            "export": {"pptx": True, "pdf": False}
        }
        
        # Giáº£ sá»­ pipeline cÃ³ phÆ°Æ¡ng thá»©c nÃ y
        slide_plan_result = self.pipeline.create_slide_from_lesson_plan(
            lesson_plan_content=lesson_plan_content,
            user_requirements=prompt,
            slide_config=slide_config
        )

        print("âœ… HoÃ n thÃ nh táº¡o Slide Plan!")
        if "json_path" in slide_plan_result:
            print(f"ğŸ“ ÄÃ£ lÆ°u táº¡i: {slide_plan_result['json_path']}")

        return {"slide_plan": slide_plan_result, "__slide_done__": True}


def should_generate_slide_plan(state: FlowState) -> bool:
    """Kiá»ƒm tra cÃ³ cáº§n táº¡o slide plan khÃ´ng."""
    form = state.get("form_data", {}) or {}
    content_types = form.get("content_types", [])
    
    if not isinstance(content_types, list):
        if isinstance(content_types, str):
            content_types = [content_types]
        else:
            content_types = []
    
    should_generate = "slide_plan" in content_types
    print(f"ğŸ¤” [should_generate_slide_plan] {should_generate} (from {content_types})")
    return should_generate


# ========================= Routing funcs =========================
def should_call_agent(state: FlowState):
    """Sau process_file: náº¿u khÃ´ng cÃ³ file => agent_retrieval, ngÆ°á»£c láº¡i embed uploaded."""
    return "agent_retrieval" if state.get("__skip__") else "embed_store_uploaded"


def first_after_filter(state: FlowState):
    """Sau filter_chunks: quyáº¿t Ä‘á»‹nh sinh plan hay quiz trÆ°á»›c dá»±a trÃªn checkbox."""
    form = state.get("form_data", {}) or {}
    
    # Láº¥y content_types tá»« form (tá»« checkbox)
    content_types = form.get("content_types", [])
    
    # DEBUG: In ra Ä‘á»ƒ kiá»ƒm tra
    print(f"ğŸ“ [DEBUG] form keys: {list(form.keys())}")
    print(f"ğŸ“ [DEBUG] content_types value: {content_types}")
    print(f"ğŸ“ [DEBUG] content_types type: {type(content_types)}")
    
    # Ensure content_types is a list
    if not isinstance(content_types, list):
        if isinstance(content_types, str):
            content_types = [content_types]
        else:
            content_types = []
    
    # Convert thÃ nh set Ä‘á»ƒ dá»… so sÃ¡nh
    outputs = set(content_types)
    print(f"ğŸ¯ [first_after_filter] User chá»n: {outputs}")
    
    # Case 1: Chá»‰ táº¡o lesson plan
    if outputs == {"lesson_plan"}:
        print("âœ… Chá»‰ táº¡o Káº¿ hoáº¡ch giáº£ng dáº¡y")
        return "generate_lesson_plan"
    
    # Case 2: Chá»‰ táº¡o quiz  
    if outputs == {"quiz"}:
        print("âœ… Chá»‰ táº¡o Quiz")
        return "generate_quiz"
    
    # Case 3: Chá»‰ táº¡o slide plan - Táº O TRá»°C TIáº¾P tá»« chunks
    if outputs == {"slide_plan"}:
        print("âœ… Chá»‰ táº¡o Slide Plan tá»« materials")
        return "generate_slide_plan"
    
    # Case 4: Táº¡o cáº£ hai lesson_plan vÃ  quiz - luÃ´n táº¡o plan trÆ°á»›c Ä‘á»ƒ quiz cÃ³ thá»ƒ sá»­ dá»¥ng
    if "lesson_plan" in outputs and "quiz" in outputs:
        print("âœ… Táº¡o cáº£ hai: Plan trÆ°á»›c, Quiz sau")
        return "generate_lesson_plan"
    
    # Case 5: Táº¡o lesson_plan vÃ  slide_plan
    if "lesson_plan" in outputs and "slide_plan" in outputs:
        print("âœ… Táº¡o Lesson Plan trÆ°á»›c, Slide Plan sau")
        return "generate_lesson_plan"
    
    # Case 6: Táº¡o quiz vÃ  slide_plan
    if "quiz" in outputs and "slide_plan" in outputs:
        print("âœ… Táº¡o Quiz trÆ°á»›c, Slide Plan sau")
        return "generate_quiz"
    
    # Case 7: Táº¡o cáº£ ba
    if "lesson_plan" in outputs and "quiz" in outputs and "slide_plan" in outputs:
        print("âœ… Táº¡o cáº£ ba: Lesson Plan trÆ°á»›c tiÃªn")
        return "generate_lesson_plan"
    
    # Default case: KhÃ´ng cÃ³ gÃ¬ Ä‘Æ°á»£c chá»n
    print("âš ï¸ KhÃ´ng cÃ³ content type nÃ o Ä‘Æ°á»£c chá»n")
    return "END"


def route_after_plan(state: FlowState):
    """Sau generate_lesson_plan: kiá»ƒm tra cÃ²n cáº§n quiz hay slide_plan khÃ´ng."""
    form = state.get("form_data", {}) or {}
    content_types = form.get("content_types", [])
    
    # Ensure it's a list
    if not isinstance(content_types, list):
        if isinstance(content_types, str):
            content_types = [content_types]
        else:
            content_types = []
    
    outputs = set(content_types)
    print(f"ğŸ“„ [route_after_plan] ÄÃ£ hoÃ n thÃ nh Plan. User chá»n: {outputs}")
    
    # Náº¿u user cÃ³ tick slide_plan vÃ  chÆ°a lÃ m slide_plan
    if "slide_plan" in outputs and not state.get("__slide_done__"):
        print("â¡ï¸ Tiáº¿p tá»¥c táº¡o Slide Plan")
        return "generate_slide_plan"
    
    # Náº¿u user cÃ³ tick quiz vÃ  chÆ°a lÃ m quiz
    if "quiz" in outputs and not state.get("__quiz_done__"):
        print("â¡ï¸ Tiáº¿p tá»¥c táº¡o Quiz")
        return "generate_quiz"
    
    print("ğŸ HoÃ n thÃ nh - chá»‰ cáº§n Plan")
    return "END"


def route_after_quiz(state: FlowState):
    """Sau generate_quiz: kiá»ƒm tra cÃ²n cáº§n plan hay slide_plan khÃ´ng."""
    form = state.get("form_data", {}) or {}
    content_types = form.get("content_types", [])
    
    # Ensure it's a list
    if not isinstance(content_types, list):
        if isinstance(content_types, str):
            content_types = [content_types]
        else:
            content_types = []
    
    outputs = set(content_types)
    print(f"ğŸ“„ [route_after_quiz] ÄÃ£ hoÃ n thÃ nh Quiz. User chá»n: {outputs}")
    
    # Náº¿u user cÃ³ tick plan vÃ  chÆ°a lÃ m plan  
    if "lesson_plan" in outputs and not state.get("__plan_done__", False):
        print("â¡ï¸ Tiáº¿p tá»¥c táº¡o Lesson Plan")
        return "generate_lesson_plan"
    
    # Náº¿u user cÃ³ tick slide_plan vÃ  chÆ°a lÃ m slide_plan
    if "slide_plan" in outputs and not state.get("__slide_done__", False):
        print("â¡ï¸ Tiáº¿p tá»¥c táº¡o Slide Plan")
        return "generate_slide_plan"
    
    print("ğŸ HoÃ n thÃ nh - chá»‰ cáº§n Quiz")
    return "END"


def route_after_slide_plan(state: FlowState):
    """Sau generate_slide_plan: kiá»ƒm tra cÃ²n cáº§n plan hay quiz khÃ´ng."""
    form = state.get("form_data", {}) or {}
    content_types = form.get("content_types", [])
    
    # Ensure it's a list
    if not isinstance(content_types, list):
        if isinstance(content_types, str):
            content_types = [content_types]
        else:
            content_types = []
    
    outputs = set(content_types)
    print(f"ğŸ“„ [route_after_slide_plan] ÄÃ£ hoÃ n thÃ nh Slide Plan. User chá»n: {outputs}")
    
    # Náº¿u user cÃ³ tick plan vÃ  chÆ°a lÃ m plan  
    if "lesson_plan" in outputs and not state.get("__plan_done__", False):
        print("â¡ï¸ Tiáº¿p tá»¥c táº¡o Lesson Plan")
        return "generate_lesson_plan"
    
    # Náº¿u user cÃ³ tick quiz vÃ  chÆ°a lÃ m quiz
    if "quiz" in outputs and not state.get("__quiz_done__", False):
        print("â¡ï¸ Tiáº¿p tá»¥c táº¡o Quiz")
        return "generate_quiz"
    
    print("ğŸ HoÃ n thÃ nh - chá»‰ cáº§n Slide Plan")
    return "END"


##Skip Logic
def should_generate_lesson_plan(state: FlowState):
    """Kiá»ƒm tra cÃ³ cáº§n táº¡o lesson plan khÃ´ng."""
    form = state.get("form_data", {}) or {}
    content_types = form.get("content_types", [])
    
    if not isinstance(content_types, list):
        if isinstance(content_types, str):
            content_types = [content_types]
        else:
            content_types = []
    
    should_generate = "lesson_plan" in content_types
    print(f"ğŸ¤” [should_generate_lesson_plan] {should_generate} (from {content_types})")
    return should_generate


def should_generate_quiz(state: FlowState):
    """Kiá»ƒm tra cÃ³ cáº§n táº¡o quiz khÃ´ng."""  
    form = state.get("form_data", {}) or {}
    content_types = form.get("content_types", [])
    
    if not isinstance(content_types, list):
        if isinstance(content_types, str):
            content_types = [content_types]
        else:
            content_types = []
    
    should_generate = "quiz" in content_types
    print(f"ğŸ¤” [should_generate_quiz] {should_generate} (from {content_types})")
    return should_generate


# ========================= LLMs =========================
llm = GPTClient(
    api_key=os.environ.get("AZURE_API_KEY"),
    endpoint=os.environ.get("AZURE_ENDPOINT"),
    model=os.environ.get("AZURE_MODEL"),
    api_version=os.environ.get("AZURE_API_VERSION")
)

# CÃ³ thá»ƒ dÃ¹ng Gemini náº¿u muá»‘n
gemini_llm = GeminiClient(
    api_key=os.environ.get("GEMINI_API_KEY"),
    model="gemini-2.5-flash"
)


# ========================= Build Graph =========================
builder = StateGraph(FlowState)

builder.add_node("generate_prompt", PromptGenerator(llm))
builder.add_node("generate_subtopics", SubtopicGenerator(llm))
builder.add_node("process_file", FileProcessor())
builder.add_node("agent_retrieval", AgentBasedRetrieval())
builder.add_node("embed_store_uploaded", EmbedAndStoreUploaded())
builder.add_node("embed_store_searched", EmbedAndStoreSearched())
builder.add_node("filter_chunks", FilterChunks())
builder.add_node("generate_lesson_plan", GenerateLessonPlan(llm))
builder.add_node("generate_quiz", GenerateQuiz(llm))
builder.add_node("generate_slide_plan", GenerateSlidePlan(llm))

builder.set_entry_point("generate_prompt")

# Linear edges
builder.add_edge("generate_prompt", "generate_subtopics")
builder.add_edge("generate_subtopics", "process_file")

# Branch after process_file
builder.add_conditional_edges(
    "process_file", should_call_agent,
    {"embed_store_uploaded": "embed_store_uploaded", "agent_retrieval": "agent_retrieval"}
)

# Continue embedding / retrieval to filter
builder.add_edge("agent_retrieval", "embed_store_searched")
builder.add_edge("embed_store_uploaded", "filter_chunks")
builder.add_edge("embed_store_searched", "filter_chunks")

# Decide which product first
builder.add_conditional_edges(
    "filter_chunks", first_after_filter,
    {
        "generate_lesson_plan": "generate_lesson_plan", 
        "generate_quiz": "generate_quiz",
        "generate_slide_plan": "generate_slide_plan",
        "END": END
    }
)

# After plan -> maybe quiz/slide_plan/end
builder.add_conditional_edges(
    "generate_lesson_plan", route_after_plan,
    {
        "generate_quiz": "generate_quiz", 
        "generate_slide_plan": "generate_slide_plan",
        "END": END
    }
)

# After quiz -> maybe plan/slide_plan/end
builder.add_conditional_edges(
    "generate_quiz", route_after_quiz,
    {
        "generate_lesson_plan": "generate_lesson_plan", 
        "generate_slide_plan": "generate_slide_plan",
        "END": END
    }
)

# After slide_plan -> maybe plan/quiz/end
builder.add_conditional_edges(
    "generate_slide_plan", route_after_slide_plan,
    {
        "generate_lesson_plan": "generate_lesson_plan",
        "generate_quiz": "generate_quiz", 
        "END": END
    }
)

# ========================= Compile & Run =========================
graph = builder.compile()


def run_flow(form_data: dict):
    """Main function Ä‘á»ƒ cháº¡y langgraph flow"""
    result = graph.invoke({"form_data": form_data})
    return result


# ========================= Test Function =========================
def test_slide_generation():
    """Test function Ä‘á»ƒ kiá»ƒm tra slide generation"""
    test_data = {
        "grade": "10",
        "subject": "ToÃ¡n",
        "topic": "PhÆ°Æ¡ng trÃ¬nh báº­c 2", 
        "duration": "45",
        "content_types": ["lesson_plan", "slide_plan"],
        "teaching_style": "interactive",
        "difficulty": "medium",
        "slide_config": {
            "color_scheme": "blue",
            "export": {"pptx": True, "pdf": False}
        }
    }
    
    print("ğŸ§ª Testing slide generation...")
    result = run_flow(test_data)
    
    print("\n" + "="*50)
    print("TEST RESULT:")
    print("="*50)
    
    if "lesson_plan" in result:
        print("âœ… Lesson Plan generated successfully")
        
    if "slide_plan" in result:
        if "error" in result["slide_plan"]:
            print(f"âŒ Slide Plan generation failed: {result['slide_plan']['error']}")
        else:
            print("âœ… Slide Plan generated successfully")
            if "json_path" in result["slide_plan"]:
                print(f"ğŸ“ Slide saved at: {result['slide_plan']['json_path']}")
    
    return result


# ========================= Viz =========================
try:
    graph.get_graph().draw_png("langgraph_flow.png")
    print("ÄÃ£ táº¡o sÆ¡ Ä‘á»“ flow táº¡i: langgraph_flow.png")
except Exception as e:
    print(f"KhÃ´ng thá»ƒ táº¡o sÆ¡ Ä‘á»“ trá»±c tiáº¿p (lá»—i: {e}). Äáº£m báº£o Ä‘Ã£ cÃ i 'pygraphviz'/'pydot' vÃ  'graphviz'.")
    print("\nÄang thá»­ xuáº¥t cáº¥u trÃºc Ä‘á»“ thá»‹ sang JSON.")
    try:
        graph_json = graph.get_graph().to_json()
        output_json_path = "langgraph_flow.json"
        with open(output_json_path, "w", encoding="utf-8") as f:
            json.dump(graph_json, f, ensure_ascii=False, indent=2)
        print(f"âœ… Xuáº¥t cáº¥u trÃºc Ä‘á»“ thá»‹: {output_json_path}")
    except Exception as json_e:
        print(f"KhÃ´ng thá»ƒ xuáº¥t Ä‘á»“ thá»‹ sang JSON: {json_e}")
        try:
            print(graph.get_graph().get_graph().to_string())
        except Exception as dot_e:
            print(f"KhÃ´ng thá»ƒ láº¥y DOT string: {dot_e}")


# ========================= Main Execution =========================
if __name__ == "__main__":
    print("ğŸš€ EduMate Flow with Slide Generation Ready!")
    print("\nAvailable functions:")
    print("- run_flow(form_data): Main langgraph flow")
    print("- run_simple_flow(form_data): Simplified flow without langgraph")
    print("- create_slide_plan_standalone(lesson_content, config): Create slides from lesson plan")
    print("- test_slide_generation(): Test slide generation functionality")
    
    # Uncomment to run test
    # test_slide_generation()
